{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae68c8b3-5cb2-427c-abc1-16c71ace8b4b",
   "metadata": {},
   "source": [
    "### Creating Virtual Bouy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "428b0d43-3516-4553-91d4-c0f65cf2fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest point on land. Searching for closest ocean point...\n",
      "Virtual buoy for Arugam Bay: (7.00, 82.00)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "ds = xr.open_dataset(\"surf_data_2020.nc\")\n",
    "\n",
    "# Arugam Bay coordinates\n",
    "spot_lat, spot_lon = 6.8399, 81.8396\n",
    "\n",
    "# Select nearest grid point\n",
    "nearest = ds.sel(latitude=spot_lat, longitude=spot_lon, method=\"nearest\")\n",
    "\n",
    "# Check if it's ocean (non-NaN swell)\n",
    "if np.isnan(nearest[\"shts\"].isel(valid_time=0)):\n",
    "    print(\"Nearest point on land. Searching for closest ocean point...\")\n",
    "\n",
    "    # Extract first timestep of swell data\n",
    "    shts_data = ds[\"shts\"].isel(valid_time=0).stack(point=(\"latitude\", \"longitude\")).dropna(\"point\")\n",
    "\n",
    "    # Compute Haversine distance\n",
    "    R = 6371  # Earth radius (km)\n",
    "    lat1, lon1 = np.radians(spot_lat), np.radians(spot_lon)\n",
    "    lat2, lon2 = np.radians(shts_data.latitude), np.radians(shts_data.longitude)\n",
    "    d = 2 * R * np.arcsin(np.sqrt(\n",
    "        np.sin((lat2 - lat1) / 2) ** 2 +\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin((lon2 - lon1) / 2) ** 2\n",
    "    ))\n",
    "\n",
    "    closest = shts_data.isel(point=d.argmin())\n",
    "    target_lat, target_lon = float(closest.latitude), float(closest.longitude)\n",
    "else:\n",
    "    print(\"Found valid offshore point.\")\n",
    "    target_lat, target_lon = float(nearest.latitude), float(nearest.longitude)\n",
    "\n",
    "print(f\"Virtual buoy for Arugam Bay: ({target_lat:.2f}, {target_lon:.2f})\")\n",
    "\n",
    "# Extract target gridpoint data (ConvLSTM input)\n",
    "features = [\"u10\", \"v10\", \"msl\", \"tp\", \"shts\", \"mpts\", \"mdts\"]\n",
    "target_data = ds[features].sel(latitude=target_lat, longitude=target_lon) # bouy-specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a99228cb-5603-49f3-9406-1c1aaa87e4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1448, 16, 21, 21, 7)\n",
      "Y_train shape: (1448, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Extract features and targets ---\n",
    "X = ds[features].to_array(dim=\"channel\").transpose(\"valid_time\", \"latitude\", \"longitude\", \"channel\")\n",
    "target_vars = [\"shts\", \"mpts\", \"mdts\", \"u10\", \"v10\"]\n",
    "Y = np.stack([target_data[var].values for var in target_vars], axis=1)\n",
    "\n",
    "# --- Clean NaNs/Infs ---\n",
    "X_values = np.nan_to_num(X.values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "Y = np.nan_to_num(Y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# --- Variable-wise normalization (feature scaling per channel) ---\n",
    "scalers = [StandardScaler().fit(X_values[..., i].reshape(-1, 1)) for i in range(X_values.shape[-1])]\n",
    "X_scaled = np.stack([scalers[i].transform(X_values[..., i].reshape(-1, 1)).reshape(X_values[..., i].shape)\n",
    "                     for i in range(X_values.shape[-1])], axis=-1)\n",
    "\n",
    "# --- Encode mdts (direction) as sine & cosine ---\n",
    "mdts_rad = np.deg2rad(Y[:, 2])\n",
    "Y = np.column_stack([Y[:, 0], Y[:, 1], np.sin(mdts_rad), np.cos(mdts_rad), Y[:, 3], Y[:, 4]])\n",
    "\n",
    "# --- Normalize Y (each column separately) ---\n",
    "Y_scaler = StandardScaler().fit(Y)\n",
    "Y_scaled = Y_scaler.transform(Y)\n",
    "\n",
    "# --- Create sliding windows ---\n",
    "def create_sequences(X, Y, lookback, lookahead):\n",
    "    X_out, Y_out = [], []\n",
    "    for i in range(len(X) - lookback - lookahead + 1):\n",
    "        X_out.append(X[i:i+lookback])\n",
    "        Y_out.append(Y[i + lookback + lookahead - 1])\n",
    "    return np.array(X_out), np.array(Y_out)\n",
    "\n",
    "LOOKBACK, LOOKAHEAD = 16, 1\n",
    "X_train, Y_train = create_sequences(X_scaled, Y_scaled, lookback=LOOKBACK, lookahead=LOOKAHEAD)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c95817-5808-4408-ab21-eda4d7376d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "False False\n",
      "X range: -4.5366464 51.446213\n",
      "Y range: -3.4284742 4.3136654\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check for NaNs/Infs\n",
    "print(np.isnan(X_train).any(), np.isinf(X_train).any())\n",
    "print(np.isnan(Y_train).any(), np.isinf(Y_train).any())\n",
    "\n",
    "# Step 2: Check value ranges\n",
    "print(\"X range:\", X_train.min(), X_train.max())\n",
    "print(\"Y range:\", Y_train.min(), Y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70404b12-2427-47fc-bd23-bc827f08497f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, 21, 21, 32)        45056     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 21, 21, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14112)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                903232    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 948806 (3.62 MB)\n",
      "Trainable params: 948742 (3.62 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, Flatten, Dense, BatchNormalization\n",
    "\n",
    "# Get the input shape from your training data\n",
    "# (lookback, height, width, channels)\n",
    "input_shape = X_train.shape[1:] \n",
    "output_shape = Y_train.shape[1] # 5\n",
    "\n",
    "model = Sequential([\n",
    "    # This layer reads the \"movie\" (8 frames of 21x21x6)\n",
    "    ConvLSTM2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        return_sequences=False, # Only output the last time step\n",
    "        input_shape=input_shape\n",
    "    ),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Flatten the final map into a 1D vector\n",
    "    Flatten(),\n",
    "    \n",
    "    # Dense layers to interpret the features\n",
    "    Dense(64, activation='relu'),\n",
    "    \n",
    "    # Output layer: 5 neurons for 5 target variables\n",
    "    # Use 'linear' activation for regression\n",
    "    Dense(output_shape, activation='linear')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbdbaedf-97f4-4a4a-9cdd-6f1c7a0376aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/37 [==============================] - 18s 424ms/step - loss: 5.8094 - mae: 1.2751 - val_loss: 0.9667 - val_mae: 0.7970\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 15s 411ms/step - loss: 1.0080 - mae: 0.8577 - val_loss: 0.9689 - val_mae: 0.7979\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 15s 404ms/step - loss: 1.0066 - mae: 0.8567 - val_loss: 0.9716 - val_mae: 0.7991\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 15s 405ms/step - loss: 1.0058 - mae: 0.8557 - val_loss: 0.9748 - val_mae: 0.8005\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 15s 409ms/step - loss: 1.0051 - mae: 0.8547 - val_loss: 0.9788 - val_mae: 0.8021\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 15s 404ms/step - loss: 1.0043 - mae: 0.8535 - val_loss: 0.9826 - val_mae: 0.8038\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 15s 401ms/step - loss: 1.0034 - mae: 0.8525 - val_loss: 0.9864 - val_mae: 0.8054\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 15s 402ms/step - loss: 1.0027 - mae: 0.8513 - val_loss: 0.9905 - val_mae: 0.8071\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 15s 400ms/step - loss: 1.0020 - mae: 0.8504 - val_loss: 0.9940 - val_mae: 0.8085\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 15s 410ms/step - loss: 1.0012 - mae: 0.8491 - val_loss: 0.9992 - val_mae: 0.8107\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 15s 408ms/step - loss: 1.0005 - mae: 0.8479 - val_loss: 1.0036 - val_mae: 0.8125\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 15s 409ms/step - loss: 0.9999 - mae: 0.8468 - val_loss: 1.0072 - val_mae: 0.8139\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.9993 - mae: 0.8458 - val_loss: 1.0120 - val_mae: 0.8159\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 15s 405ms/step - loss: 0.9989 - mae: 0.8447 - val_loss: 1.0160 - val_mae: 0.8175\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.9984 - mae: 0.8437 - val_loss: 1.0196 - val_mae: 0.8190\n",
      "Epoch 16/20\n",
      "37/37 [==============================] - 15s 411ms/step - loss: 0.9981 - mae: 0.8430 - val_loss: 1.0230 - val_mae: 0.8204\n",
      "Epoch 17/20\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.9977 - mae: 0.8421 - val_loss: 1.0263 - val_mae: 0.8217\n",
      "Epoch 18/20\n",
      "37/37 [==============================] - 16s 435ms/step - loss: 0.9975 - mae: 0.8413 - val_loss: 1.0304 - val_mae: 0.8234\n",
      "Epoch 19/20\n",
      "37/37 [==============================] - 15s 403ms/step - loss: 0.9972 - mae: 0.8406 - val_loss: 1.0333 - val_mae: 0.8246\n",
      "Epoch 20/20\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.9970 - mae: 0.8400 - val_loss: 1.0354 - val_mae: 0.8255\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "\n",
      "--- Offshore Forecast (Input for SWAN) ---\n",
      "Swell Height:   1.12 m\n",
      "Swell Period:   8.28 s\n",
      "Swell Direction:0.34°\n",
      "U-Wind:         -0.73 m/s\n",
      "V-Wind:         0.43 m/s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make a Prediction (next 6 hours)\n",
    "last_sequence = np.expand_dims(X_scaled[-LOOKBACK:], axis=0)\n",
    "pred_scaled = model.predict(last_sequence)\n",
    "pred_real = Y_scaler.inverse_transform(pred_scaled)\n",
    "\n",
    "print(\"\\n--- Offshore Forecast (Input for SWAN) ---\")\n",
    "print(f\"Swell Height:   {pred_real[0, 0]:.2f} m\")\n",
    "print(f\"Swell Period:   {pred_real[0, 1]:.2f} s\")\n",
    "print(f\"Swell Direction:{pred_real[0, 2]:.2f}°\")\n",
    "print(f\"U-Wind:         {pred_real[0, 3]:.2f} m/s\")\n",
    "print(f\"V-Wind:         {pred_real[0, 4]:.2f} m/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfab4068-50f8-4c14-96ed-6b22fde6783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 85ms/step\n",
      "\n",
      "--- Validation Metrics ---\n",
      "MAE :  1.1750\n",
      "RMSE:  1.9228\n",
      "R²   :  -0.2918\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate model performance ---\n",
    "# Predict on validation data\n",
    "val_size = int(0.2 * len(X_train))\n",
    "Y_val_true = Y_train[-val_size:]\n",
    "Y_val_pred = model.predict(X_train[-val_size:])\n",
    "\n",
    "# Inverse transform back to original scale\n",
    "Y_val_true_real = Y_scaler.inverse_transform(Y_val_true)\n",
    "Y_val_pred_real = Y_scaler.inverse_transform(Y_val_pred)\n",
    "\n",
    "# Compute metrics\n",
    "mae = mean_absolute_error(Y_val_true_real, Y_val_pred_real)\n",
    "rmse = np.sqrt(mean_squared_error(Y_val_true_real, Y_val_pred_real))\n",
    "r2 = r2_score(Y_val_true_real, Y_val_pred_real)\n",
    "\n",
    "print(\"\\n--- Validation Metrics ---\")\n",
    "print(f\"MAE :  {mae:.4f}\")\n",
    "print(f\"RMSE:  {rmse:.4f}\")\n",
    "print(f\"R²   :  {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "092dba5f-e8a9-42bd-ac9d-a70d95487735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shts | MAE=0.159, RMSE=0.203, R²=-0.150\n",
      " mpts | MAE=0.825, RMSE=0.998, R²=-0.291\n",
      " mdts | MAE=0.450, RMSE=0.498, R²=-0.319\n",
      "  u10 | MAE=0.448, RMSE=0.581, R²=-0.285\n",
      "  v10 | MAE=1.846, RMSE=2.253, R²=-0.124\n"
     ]
    }
   ],
   "source": [
    "for i, var in enumerate([\"shts\", \"mpts\", \"mdts\", \"u10\", \"v10\"]):\n",
    "    mae_i = mean_absolute_error(Y_val_true_real[:, i], Y_val_pred_real[:, i])\n",
    "    rmse_i = np.sqrt(mean_squared_error(Y_val_true_real[:, i], Y_val_pred_real[:, i]))\n",
    "    r2_i = r2_score(Y_val_true_real[:, i], Y_val_pred_real[:, i])\n",
    "    print(f\"{var:>5s} | MAE={mae_i:.3f}, RMSE={rmse_i:.3f}, R²={r2_i:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541bd459-9613-4de1-bd3c-27f8458edc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# --- Make a Prediction ---\n",
    "# Get the last 48 hours of data to predict the next 6 hours\n",
    "last_sequence = X_scaled[-LOOKBACK:]\n",
    "last_sequence = np.expand_dims(last_sequence, axis=0) # Add batch dimension\n",
    "\n",
    "predicted_scaled = model.predict(last_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1c826-6d1a-4599-9c7e-0c97d752923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Y_scaler we created in Step 2\n",
    "predicted_real = Y_scaler.inverse_transform(predicted_scaled)\n",
    "\n",
    "print(\"--- Offshore Forecast (Input for SWAN) ---\")\n",
    "print(f\"Swell Height: {predicted_real[0, 0]:.2f} m\")\n",
    "print(f\"Swell Period: {predicted_real[0, 1]:.2f} s\")\n",
    "print(f\"Swell Direction: {predicted_real[0, 2]:.2f} degrees\")\n",
    "print(f\"U-Wind: {predicted_real[0, 3]:.2f} m/s\")\n",
    "print(f\"V-Wind: {predicted_real[0, 4]:.2f} m/s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a19f17d-3acb-4b11-8450-d934d14ed4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    ConvLSTM2D, Conv3D, BatchNormalization, Input, \n",
    "    TimeDistributed, Conv2D, Dropout\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "# CONFIGURATION\n",
    "DATA_PATH = \"../surf_data_2024.nc\"\n",
    "SPOT_LAT, SPOT_LON = 6.8399, 81.8396\n",
    "LOOKBACK_HOURS = 19  # Match reference paper's temporal window\n",
    "LOOKAHEAD_HOURS = 1   # Predict next frame\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8  # Smaller due to memory constraints\n",
    "SPATIAL_SIZE = 21  # Your data size (can't increase without more data)\n",
    "\n",
    "INPUT_FEATURES = [\"u10\", \"v10\", \"msl\", \"shts\", \"mpts\", \"mdts\"]\n",
    "TARGET_FEATURES = [\"shts\", \"mpts\", \"mdts\"]  # Predict wave fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1175f33-0372-4e8d-815c-44e7e7549d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING (From previous artifact)\n",
    "# ======================================================================\n",
    "def create_ocean_mask(ds, threshold=0.5):\n",
    "    \"\"\"Create mask to exclude land points.\"\"\"\n",
    "    shts_data = ds[\"shts\"].values\n",
    "    nan_ratio = np.isnan(shts_data).sum(axis=0) / shts_data.shape[0]\n",
    "    ocean_mask = nan_ratio < threshold\n",
    "    \n",
    "    valid_points = ocean_mask.sum()\n",
    "    print(f\"üåä Ocean Mask: {valid_points} / {ocean_mask.size} points ({100*valid_points/ocean_mask.size:.1f}%)\")\n",
    "    return ocean_mask\n",
    "\n",
    "\n",
    "def find_nearest_ocean_point(ds, lat, lon):\n",
    "    \"\"\"Find nearest valid ocean point.\"\"\"\n",
    "    nearest = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "    \n",
    "    if not np.isnan(nearest[\"shts\"].isel(valid_time=0)):\n",
    "        return float(nearest.latitude), float(nearest.longitude)\n",
    "    \n",
    "    shts_data = ds[\"shts\"].isel(valid_time=0).stack(\n",
    "        point=(\"latitude\", \"longitude\")\n",
    "    ).dropna(\"point\")\n",
    "    \n",
    "    R = 6371\n",
    "    lat1, lon1 = np.radians(lat), np.radians(lon)\n",
    "    lat2 = np.radians(shts_data.latitude)\n",
    "    lon2 = np.radians(shts_data.longitude)\n",
    "    \n",
    "    dlat = (lat2 - lat1) / 2\n",
    "    dlon = (lon2 - lon1) / 2\n",
    "    \n",
    "    a = np.sin(dlat)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon)**2\n",
    "    distance = 2 * R * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    closest = shts_data.isel(point=distance.argmin())\n",
    "    return float(closest.latitude), float(closest.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdeffefe-9832-4b79-8134-2755c8b37be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRAME-BASED FEATURE ENGINEERING\n",
    "# ======================================================================\n",
    "def engineer_frames(ds, ocean_mask):\n",
    "    \"\"\"\n",
    "    Prepare spatiotemporal frames for prediction.\n",
    "    Unlike point prediction, this preserves spatial structure.\n",
    "    \"\"\"\n",
    "    # Input frames: All 6 features across space\n",
    "    X = ds[INPUT_FEATURES].to_array(dim=\"channel\").transpose(\n",
    "        \"valid_time\", \"latitude\", \"longitude\", \"channel\"\n",
    "    ).values\n",
    "    \n",
    "    # Output frames: Only wave parameters (3 features)\n",
    "    y = ds[TARGET_FEATURES].to_array(dim=\"channel\").transpose(\n",
    "        \"valid_time\", \"latitude\", \"longitude\", \"channel\"\n",
    "    ).values\n",
    "    \n",
    "    # Apply ocean mask to both\n",
    "    mask_3d_X = np.broadcast_to(ocean_mask[..., np.newaxis], X.shape[1:])\n",
    "    mask_3d_y = np.broadcast_to(ocean_mask[..., np.newaxis], y.shape[1:])\n",
    "    \n",
    "    X[:, ~mask_3d_X] = 0.0\n",
    "    y[:, ~mask_3d_y] = 0.0\n",
    "    \n",
    "    # Fill remaining NaNs with channel means\n",
    "    for i in range(X.shape[-1]):\n",
    "        channel_mean = np.nanmean(X[..., i])\n",
    "        X[..., i] = np.nan_to_num(X[..., i], nan=channel_mean)\n",
    "    \n",
    "    for i in range(y.shape[-1]):\n",
    "        channel_mean = np.nanmean(y[..., i])\n",
    "        y[..., i] = np.nan_to_num(y[..., i], nan=channel_mean)\n",
    "    \n",
    "    print(f\"üìä Frames prepared:\")\n",
    "    print(f\"   Input: {X.shape} (time, lat, lon, channels)\")\n",
    "    print(f\"   Output: {y.shape}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def normalize_frames(X, y):\n",
    "    \"\"\"Normalize each channel independently.\"\"\"\n",
    "    X_scaled = np.zeros_like(X)\n",
    "    y_scaled = np.zeros_like(y)\n",
    "    \n",
    "    scalers_X = []\n",
    "    scalers_y = []\n",
    "    \n",
    "    # Normalize input channels\n",
    "    for i in range(X.shape[-1]):\n",
    "        scaler = StandardScaler()\n",
    "        channel = X[..., i].reshape(-1, 1)\n",
    "        X_scaled[..., i] = scaler.fit_transform(channel).reshape(X[..., i].shape)\n",
    "        scalers_X.append(scaler)\n",
    "    \n",
    "    # Normalize output channels\n",
    "    for i in range(y.shape[-1]):\n",
    "        scaler = StandardScaler()\n",
    "        channel = y[..., i].reshape(-1, 1)\n",
    "        y_scaled[..., i] = scaler.fit_transform(channel).reshape(y[..., i].shape)\n",
    "        scalers_y.append(scaler)\n",
    "    \n",
    "    return X_scaled, y_scaled, scalers_X, scalers_y\n",
    "\n",
    "\n",
    "def create_frame_sequences(X, y, lookback, lookahead):\n",
    "    \"\"\"\n",
    "    Create sequences where:\n",
    "    - Input: [lookback] frames of multi-channel data\n",
    "    - Output: [lookahead] frame(s) of wave parameters\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    \n",
    "    for i in range(len(X) - lookback - lookahead + 1):\n",
    "        X_seq.append(X[i:i + lookback])\n",
    "        y_seq.append(y[i + lookback + lookahead - 1])  # Single frame prediction\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40e1cb6-d5be-4a16-bece-c6cc62f064a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED ARCHITECTURES\n",
    "# ======================================================================\n",
    "\n",
    "def build_model_v3_encoder_decoder(input_shape, output_channels):\n",
    "    \"\"\"\n",
    "    Architecture V3: Encoder-Decoder ConvLSTM\n",
    "    Based on spatiotemporal forecasting best practices.\n",
    "    \n",
    "    Similar to the reference paper but adapted for wave forecasting.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder: Extract spatiotemporal features\n",
    "    x = ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        return_sequences=True,\n",
    "        name='encoder_1'\n",
    "    )(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        return_sequences=True,\n",
    "        name='encoder_2'\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = ConvLSTM2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        return_sequences=True,\n",
    "        name='encoder_3'\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Conv3D for temporal aggregation (as in reference paper)\n",
    "    x = Conv3D(\n",
    "        filters=output_channels,\n",
    "        kernel_size=(3, 3, 3),\n",
    "        padding='same',\n",
    "        activation='linear',\n",
    "        name='output_conv3d'\n",
    "    )(x)\n",
    "    \n",
    "    # Take the last timestep as prediction\n",
    "    outputs = x[:, -1, :, :, :]\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='ConvLSTM_EncoderDecoder')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_v4_deep_stack(input_shape, output_channels):\n",
    "    \"\"\"\n",
    "    Architecture V4: Deep Stacked ConvLSTM\n",
    "    More layers, better feature extraction.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        ConvLSTM2D(\n",
    "            128, (3, 3),\n",
    "            padding='same',\n",
    "            return_sequences=True,\n",
    "            input_shape=input_shape,\n",
    "            name='convlstm_1'\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        ConvLSTM2D(\n",
    "            64, (3, 3),\n",
    "            padding='same',\n",
    "            return_sequences=True,\n",
    "            name='convlstm_2'\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        ConvLSTM2D(\n",
    "            32, (3, 3),\n",
    "            padding='same',\n",
    "            return_sequences=True,\n",
    "            name='convlstm_3'\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Final Conv3D for prediction\n",
    "        Conv3D(\n",
    "            output_channels,\n",
    "            kernel_size=(3, 3, 3),\n",
    "            padding='same',\n",
    "            activation='linear',\n",
    "            name='prediction_layer'\n",
    "        )\n",
    "    ], name='DeepStack_ConvLSTM')\n",
    "    \n",
    "    # Extract last frame\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: x[:, -1, :, :, :]))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_v5_hybrid(input_shape, output_channels, buoy_location):\n",
    "    \"\"\"\n",
    "    Architecture V5: Hybrid Spatial + Point Prediction\n",
    "    Combines frame prediction with point-specific forecasting.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Shared spatiotemporal encoder\n",
    "    x = ConvLSTM2D(64, (3, 3), padding='same', return_sequences=True)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = ConvLSTM2D(32, (3, 3), padding='same', return_sequences=True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Branch 1: Full frame prediction\n",
    "    frame_out = Conv3D(\n",
    "        output_channels,\n",
    "        kernel_size=(3, 3, 3),\n",
    "        padding='same',\n",
    "        activation='linear'\n",
    "    )(x)\n",
    "    frame_out = frame_out[:, -1, :, :, :]  # Last timestep\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=frame_out, name='Hybrid_ConvLSTM')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fc00e1-05fe-46e6-a2b7-2759683d5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION FOR FRAME PREDICTIONS\n",
    "# ======================================================================\n",
    "def evaluate_frame_model(model, X_val, y_val, scalers_y, buoy_lat, buoy_lon, ds):\n",
    "    \"\"\"\n",
    "    Evaluate model on:\n",
    "    1. Overall spatial prediction\n",
    "    2. Point prediction at buoy location\n",
    "    \"\"\"\n",
    "    y_pred_scaled = model.predict(X_val, verbose=0)\n",
    "    \n",
    "    # Inverse transform\n",
    "    y_true = np.zeros_like(y_val)\n",
    "    y_pred = np.zeros_like(y_pred_scaled)\n",
    "    \n",
    "    for i in range(y_val.shape[-1]):\n",
    "        scaler = scalers_y[i]\n",
    "        y_true[..., i] = scaler.inverse_transform(\n",
    "            y_val[..., i].reshape(-1, 1)\n",
    "        ).reshape(y_val[..., i].shape)\n",
    "        y_pred[..., i] = scaler.inverse_transform(\n",
    "            y_pred_scaled[..., i].reshape(-1, 1)\n",
    "        ).reshape(y_pred_scaled[..., i].shape)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SPATIAL PREDICTION METRICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Overall spatial metrics\n",
    "    mae_overall = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "    rmse_overall = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))\n",
    "    \n",
    "    print(f\"Overall Spatial | MAE={mae_overall:.4f}, RMSE={rmse_overall:.4f}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Per-channel metrics\n",
    "    for i, var in enumerate(TARGET_FEATURES):\n",
    "        mae = mean_absolute_error(y_true[..., i].flatten(), y_pred[..., i].flatten())\n",
    "        rmse = np.sqrt(mean_squared_error(y_true[..., i].flatten(), y_pred[..., i].flatten()))\n",
    "        print(f\"{var:>6s} | MAE={mae:.3f}, RMSE={rmse:.3f}\")\n",
    "    \n",
    "    # Point-specific metrics at buoy location\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"BUOY LOCATION METRICS ({buoy_lat:.2f}¬∞N, {buoy_lon:.2f}¬∞E)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Find buoy indices in grid\n",
    "    lats = ds.latitude.values\n",
    "    lons = ds.longitude.values\n",
    "    lat_idx = np.argmin(np.abs(lats - buoy_lat))\n",
    "    lon_idx = np.argmin(np.abs(lons - buoy_lon))\n",
    "    \n",
    "    y_true_buoy = y_true[:, lat_idx, lon_idx, :]\n",
    "    y_pred_buoy = y_pred[:, lat_idx, lon_idx, :]\n",
    "    \n",
    "    for i, var in enumerate(TARGET_FEATURES):\n",
    "        mae = mean_absolute_error(y_true_buoy[:, i], y_pred_buoy[:, i])\n",
    "        rmse = np.sqrt(mean_squared_error(y_true_buoy[:, i], y_pred_buoy[:, i]))\n",
    "        r2 = r2_score(y_true_buoy[:, i], y_pred_buoy[:, i])\n",
    "        print(f\"{var:>6s} | MAE={mae:.3f}, RMSE={rmse:.3f}, R¬≤={r2:.3f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return y_true, y_pred, y_true_buoy, y_pred_buoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e013c6-054f-4ab5-b608-f21f158436fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä ENHANCED CONVLSTM WITH FRAME PREDICTION\n",
      "======================================================================\n",
      "üìç Buoy: (7.00¬∞N, 82.00¬∞E)\n",
      "üåä Ocean Mask: 93 / 441 points (21.1%)\n",
      "üìä Frames prepared:\n",
      "   Input: (1464, 21, 21, 6) (time, lat, lon, channels)\n",
      "   Output: (1464, 21, 21, 3)\n",
      "\n",
      "üîÑ Creating sequences (lookback=19)...\n",
      "   Sequences: X=(1445, 19, 21, 21, 6), y=(1445, 21, 21, 3)\n",
      "\n",
      "üèóÔ∏è Building model...\n",
      "Using Architecture V3: Encoder-Decoder ConvLSTM\n",
      "Model: \"ConvLSTM_EncoderDecoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 19, 21, 21, 6)]   0         \n",
      "                                                                 \n",
      " encoder_1 (ConvLSTM2D)      (None, 19, 21, 21, 64)    161536    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 19, 21, 21, 64)    256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " encoder_2 (ConvLSTM2D)      (None, 19, 21, 21, 64)    295168    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 19, 21, 21, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " encoder_3 (ConvLSTM2D)      (None, 19, 21, 21, 32)    110720    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 19, 21, 21, 32)    128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " output_conv3d (Conv3D)      (None, 19, 21, 21, 3)     2595      \n",
      "                                                                 \n",
      " tf.__operators__.getitem (  (None, 21, 21, 3)         0         \n",
      " SlicingOpLambda)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 570659 (2.18 MB)\n",
      "Trainable params: 570339 (2.18 MB)\n",
      "Non-trainable params: 320 (1.25 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "üöÄ Training for up to 100 epochs...\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - ETA: 0s - loss: 0.1058 - mae: 0.1757\n",
      "Epoch 1: val_loss improved from inf to 0.26090, saving model to best_wave_model.keras\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The following argument(s) are not supported with the native Keras format: ['options']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müöÄ Training for up to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_seq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALIDATION_SPLIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     74\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m     77\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(VALIDATION_SPLIT \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_seq))\n",
      "File \u001b[1;32mC:\\Hasi\\WorkShit\\Ceylon-Surfers\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Hasi\\WorkShit\\Ceylon-Surfers\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:142\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         )\n\u001b[0;32m    146\u001b[0m     saving_lib\u001b[38;5;241m.\u001b[39msave_model(model, filepath)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m# Legacy case\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The following argument(s) are not supported with the native Keras format: ['options']"
     ]
    }
   ],
   "source": [
    "# MAIN EXECUTION\n",
    "# ======================================================================\n",
    "\n",
    "print(\"üåä ENHANCED CONVLSTM WITH FRAME PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load data\n",
    "ds = xr.open_dataset(DATA_PATH)\n",
    "buoy_lat, buoy_lon = find_nearest_ocean_point(ds, SPOT_LAT, SPOT_LON)\n",
    "print(f\"üìç Buoy: ({buoy_lat:.2f}¬∞N, {buoy_lon:.2f}¬∞E)\")\n",
    "\n",
    "# Create ocean mask\n",
    "ocean_mask = create_ocean_mask(ds)\n",
    "\n",
    "# Prepare frames\n",
    "X, y = engineer_frames(ds, ocean_mask)\n",
    "\n",
    "# Normalize\n",
    "X_scaled, y_scaled, scalers_X, scalers_y = normalize_frames(X, y)\n",
    "\n",
    "# Create sequences\n",
    "print(f\"\\nüîÑ Creating sequences (lookback={LOOKBACK_HOURS})...\")\n",
    "X_seq, y_seq = create_frame_sequences(X_scaled, y_scaled, LOOKBACK_HOURS, LOOKAHEAD_HOURS)\n",
    "print(f\"   Sequences: X={X_seq.shape}, y={y_seq.shape}\")\n",
    "\n",
    "# Build model - Choose architecture\n",
    "print(\"\\nüèóÔ∏è Building model...\")\n",
    "ARCHITECTURE = \"v3\"  # Change to \"v4\" or \"v5\" to try different architectures\n",
    "\n",
    "if ARCHITECTURE == \"v3\":\n",
    "    model = build_model_v3_encoder_decoder(X_seq.shape[1:], y_seq.shape[-1])\n",
    "    print(\"Using Architecture V3: Encoder-Decoder ConvLSTM\")\n",
    "elif ARCHITECTURE == \"v4\":\n",
    "    model = build_model_v4_deep_stack(X_seq.shape[1:], y_seq.shape[-1])\n",
    "    print(\"Using Architecture V4: Deep Stacked ConvLSTM\")\n",
    "else:\n",
    "    model = build_model_v5_hybrid(X_seq.shape[1:], y_seq.shape[-1], (buoy_lat, buoy_lon))\n",
    "    print(\"Using Architecture V5: Hybrid ConvLSTM\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,  # Match reference paper\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_wave_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(f\"\\nüöÄ Training for up to {EPOCHS} epochs...\")\n",
    "history = model.fit(\n",
    "    X_seq, y_seq,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "val_size = int(VALIDATION_SPLIT * len(X_seq))\n",
    "y_true, y_pred, y_true_buoy, y_pred_buoy = evaluate_frame_model(\n",
    "    model, X_seq[-val_size:], y_seq[-val_size:], \n",
    "    scalers_y, buoy_lat, buoy_lon, ds\n",
    ")\n",
    "\n",
    "# Forecast next frame\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîÆ FORECAST (Next Frame)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "last_seq = np.expand_dims(X_scaled[-LOOKBACK_HOURS:], axis=0)\n",
    "forecast_scaled = model.predict(last_seq, verbose=0)[0]\n",
    "\n",
    "# Inverse transform forecast\n",
    "forecast = np.zeros_like(forecast_scaled)\n",
    "for i in range(forecast_scaled.shape[-1]):\n",
    "    forecast[..., i] = scalers_y[i].inverse_transform(\n",
    "        forecast_scaled[..., i].reshape(-1, 1)\n",
    "    ).reshape(forecast_scaled[..., i].shape)\n",
    "\n",
    "# Extract buoy location forecast\n",
    "lats = ds.latitude.values\n",
    "lons = ds.longitude.values\n",
    "lat_idx = np.argmin(np.abs(lats - buoy_lat))\n",
    "lon_idx = np.argmin(np.abs(lons - buoy_lon))\n",
    "\n",
    "buoy_forecast = forecast[lat_idx, lon_idx, :]\n",
    "\n",
    "print(f\"At Buoy Location ({buoy_lat:.2f}¬∞N, {buoy_lon:.2f}¬∞E):\")\n",
    "print(f\"  Swell Height:    {buoy_forecast[0]:.2f} m\")\n",
    "print(f\"  Swell Period:    {buoy_forecast[1]:.2f} s\")\n",
    "print(f\"  Swell Direction: {buoy_forecast[2]:.1f}¬∞\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796e7ced-79c7-406d-8201-21afffc551f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Hasi\\WorkShit\\Ceylon-Surfers\\venv\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, Flatten, Dense, BatchNormalization, Dropout, PReLU\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7149a97-7e00-4e03-9f46-b079e187dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "DATA_PATH = \"surf_data_2020.nc\"\n",
    "SPOT_LAT, SPOT_LON = 6.8399, 81.8396  # Arugam Bay\n",
    "LOOKBACK_HOURS = 16\n",
    "LOOKAHEAD_HOURS = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Feature and target configuration\n",
    "INPUT_FEATURES = [\"u10\", \"v10\", \"msl\", \"tp\", \"shts\", \"mpts\", \"mdts\"]\n",
    "TARGET_VARS = [\"shts\", \"mpts\", \"mdts_sin\", \"mdts_cos\", \"wind_speed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e875a0-b260-40ec-9960-00b86b23e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADING & BUOY SELECTION\n",
    "def find_nearest_ocean_point(ds, lat, lon):\n",
    "    \"\"\"Find nearest valid ocean point using Haversine distance.\"\"\"\n",
    "    nearest = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "    \n",
    "    if not np.isnan(nearest[\"shts\"].isel(valid_time=0)):\n",
    "        print(\"Found valid offshore point\")\n",
    "        return float(nearest.latitude), float(nearest.longitude)\n",
    "    \n",
    "    print(\"Nearest point on land. Searching for closest ocean point...\")\n",
    "    shts_data = ds[\"shts\"].isel(valid_time=0).stack(\n",
    "        point=(\"latitude\", \"longitude\")\n",
    "    ).dropna(\"point\")\n",
    "    \n",
    "    # Haversine distance\n",
    "    R = 6371  # Earth radius (km)\n",
    "    lat1, lon1 = np.radians(lat), np.radians(lon)\n",
    "    lat2 = np.radians(shts_data.latitude)\n",
    "    lon2 = np.radians(shts_data.longitude)\n",
    "    \n",
    "    dlat = (lat2 - lat1) / 2\n",
    "    dlon = (lon2 - lon1) / 2\n",
    "    \n",
    "    a = np.sin(dlat)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon)**2\n",
    "    distance = 2 * R * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    closest = shts_data.isel(point=distance.argmin())\n",
    "    return float(closest.latitude), float(closest.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4413b1-c7e6-4186-a323-8363fa9f0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "def engineer_features(ds, buoy_lat, buoy_lon):\n",
    "    \"\"\"Extract and engineer features for model input.\"\"\"\n",
    "    # Spatial features (full grid)\n",
    "    X = ds[INPUT_FEATURES].to_array(dim=\"channel\").transpose(\n",
    "        \"valid_time\", \"latitude\", \"longitude\", \"channel\"\n",
    "    ).values\n",
    "    \n",
    "    # Target point features\n",
    "    buoy_data = ds.sel(latitude=buoy_lat, longitude=buoy_lon)\n",
    "    \n",
    "    # Wind speed from components\n",
    "    wind_speed = np.sqrt(buoy_data[\"u10\"]**2 + buoy_data[\"v10\"]**2).values\n",
    "    \n",
    "    # Direction encoding (sine/cosine)\n",
    "    mdts_rad = np.deg2rad(buoy_data[\"mdts\"].values)\n",
    "    mdts_sin = np.sin(mdts_rad)\n",
    "    mdts_cos = np.cos(mdts_rad)\n",
    "    \n",
    "    # Target array\n",
    "    y = np.column_stack([\n",
    "        buoy_data[\"shts\"].values,\n",
    "        buoy_data[\"mpts\"].values,\n",
    "        mdts_sin,\n",
    "        mdts_cos,\n",
    "        wind_speed\n",
    "    ])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e85f1e2-736b-471b-81f8-d76b3effc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "def preprocess_data(X, y):\n",
    "    \"\"\"Clean, normalize, and scale data.\"\"\"\n",
    "    # Remove NaN/Inf\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Normalize X per channel\n",
    "    X_scaled = np.zeros_like(X)\n",
    "    scalers_X = []\n",
    "    \n",
    "    for i in range(X.shape[-1]):\n",
    "        scaler = StandardScaler()\n",
    "        channel = X[..., i].reshape(-1, 1)\n",
    "        X_scaled[..., i] = scaler.fit_transform(channel).reshape(X[..., i].shape)\n",
    "        scalers_X.append(scaler)\n",
    "    \n",
    "    # Normalize y\n",
    "    scaler_y = StandardScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y)\n",
    "    \n",
    "    return X_scaled, y_scaled, scalers_X, scaler_y\n",
    "\n",
    "def create_sequences(X, y, lookback, lookahead):\n",
    "    \"\"\"Generate sliding window sequences.\"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    \n",
    "    for i in range(len(X) - lookback - lookahead + 1):\n",
    "        X_seq.append(X[i:i + lookback])\n",
    "        y_seq.append(y[i + lookback + lookahead - 1])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54b4bfe-6238-4b92-8bf1-e8bd158face3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL BUILDING\n",
    "def build_model(input_shape, output_dim):\n",
    "    \"\"\"Build ConvLSTM2D model for spatiotemporal forecasting.\"\"\"\n",
    "    model = Sequential([\n",
    "        ConvLSTM2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same',\n",
    "            return_sequences=False,\n",
    "            input_shape=input_shape\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dense(64),\n",
    "        PReLU(),\n",
    "        Dropout(0.2),\n",
    "        Dense(output_dim, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cd586c2-22c6-4391-9fc4-4f2f66131f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "def evaluate_model(model, X_val, y_val, scaler_y, target_names):\n",
    "    \"\"\"Comprehensive model evaluation.\"\"\"\n",
    "    y_pred_scaled = model.predict(X_val, verbose=0)\n",
    "    \n",
    "    # Inverse transform\n",
    "    y_true = scaler_y.inverse_transform(y_val)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    \n",
    "    # Overall metrics\n",
    "    mae_overall = mean_absolute_error(y_true, y_pred)\n",
    "    rmse_overall = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2_overall = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDATION METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Overall | MAE={mae_overall:.4f}, RMSE={rmse_overall:.4f}, R²={r2_overall:.4f}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Per-variable metrics\n",
    "    for i, var in enumerate(target_names):\n",
    "        mae_i = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        rmse_i = np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i]))\n",
    "        r2_i = r2_score(y_true[:, i], y_pred[:, i])\n",
    "        print(f\"{var:>12s} | MAE={mae_i:.3f}, RMSE={rmse_i:.3f}, R²={r2_i:.3f}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c2bda4e-9439-4288-9fd1-309d824a0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Nearest point on land. Searching for closest ocean point...\n",
      "Virtual buoy: (7.00°N, 82.00°E)\n",
      "\n",
      "Engineering features...\n",
      "Spatial input shape: (1464, 21, 21, 7)\n",
      "Target shape: (1464, 5)\n",
      "Preprocessing data...\n",
      "Creating sequences (lookback=16, lookahead=1)...\n",
      "Sequence shape: X=(1448, 16, 21, 21, 7), y=(1448, 5)\n",
      "\n",
      "Building model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, 21, 21, 32)        45056     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 21, 21, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14112)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                903232    \n",
      "                                                                 \n",
      " p_re_lu (PReLU)             (None, 64)                64        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 948805 (3.62 MB)\n",
      "Trainable params: 948741 (3.62 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training for 20 epochs...\n",
      "Epoch 1/20\n",
      "37/37 [==============================] - 37s 931ms/step - loss: 8.2022 - mae: 1.4977 - val_loss: 1.0367 - val_mae: 0.8204\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 32s 876ms/step - loss: 0.7540 - mae: 0.6701 - val_loss: 0.9744 - val_mae: 0.7902\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 33s 893ms/step - loss: 0.6764 - mae: 0.6196 - val_loss: 1.0090 - val_mae: 0.8106\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 33s 907ms/step - loss: 0.6030 - mae: 0.5853 - val_loss: 1.0119 - val_mae: 0.8054\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 32s 880ms/step - loss: 0.5740 - mae: 0.5651 - val_loss: 0.8224 - val_mae: 0.7095\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 33s 889ms/step - loss: 0.5784 - mae: 0.5709 - val_loss: 0.8989 - val_mae: 0.7620\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 33s 890ms/step - loss: 0.5278 - mae: 0.5467 - val_loss: 0.7589 - val_mae: 0.6964\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 34s 922ms/step - loss: 0.5008 - mae: 0.5289 - val_loss: 0.8139 - val_mae: 0.7208\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 33s 882ms/step - loss: 0.4942 - mae: 0.5304 - val_loss: 0.7451 - val_mae: 0.6774\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 33s 894ms/step - loss: 0.4914 - mae: 0.5294 - val_loss: 0.7234 - val_mae: 0.6662\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 33s 907ms/step - loss: 0.4843 - mae: 0.5294 - val_loss: 0.6853 - val_mae: 0.6470\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 32s 876ms/step - loss: 0.4612 - mae: 0.5159 - val_loss: 0.5990 - val_mae: 0.5994\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 33s 904ms/step - loss: 0.4760 - mae: 0.5181 - val_loss: 0.6784 - val_mae: 0.6525\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 33s 891ms/step - loss: 0.4515 - mae: 0.5126 - val_loss: 0.6424 - val_mae: 0.6326\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - 34s 933ms/step - loss: 0.4178 - mae: 0.4902 - val_loss: 0.6648 - val_mae: 0.6450\n",
      "Epoch 16/20\n",
      "37/37 [==============================] - 35s 938ms/step - loss: 0.3947 - mae: 0.4742 - val_loss: 0.6138 - val_mae: 0.6247\n",
      "Epoch 17/20\n",
      "37/37 [==============================] - 35s 944ms/step - loss: 0.3741 - mae: 0.4658 - val_loss: 0.6626 - val_mae: 0.6418\n",
      "Epoch 18/20\n",
      "37/37 [==============================] - 33s 899ms/step - loss: 0.3646 - mae: 0.4602 - val_loss: 0.5742 - val_mae: 0.5674\n",
      "Epoch 19/20\n",
      "37/37 [==============================] - 33s 899ms/step - loss: 0.3531 - mae: 0.4478 - val_loss: 0.7031 - val_mae: 0.6288\n",
      "Epoch 20/20\n",
      "37/37 [==============================] - 33s 885ms/step - loss: 0.3475 - mae: 0.4454 - val_loss: 0.9053 - val_mae: 0.6932\n",
      "\n",
      "============================================================\n",
      "VALIDATION METRICS\n",
      "============================================================\n",
      "Overall | MAE=0.6361, RMSE=1.1437, R²=-0.0946\n",
      "------------------------------------------------------------\n",
      "        shts | MAE=0.143, RMSE=0.199, R²=-0.108\n",
      "        mpts | MAE=0.691, RMSE=0.840, R²=0.089\n",
      "    mdts_sin | MAE=0.291, RMSE=0.339, R²=0.381\n",
      "    mdts_cos | MAE=0.316, RMSE=0.515, R²=-0.011\n",
      "  wind_speed | MAE=1.739, RMSE=2.327, R²=-0.825\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "FORECAST (Next 6 Hours)\n",
      "============================================================\n",
      "Swell Height:    1.19 m\n",
      "Swell Period:    8.04 s\n",
      "Swell Direction: 130.0°\n",
      "Wind Speed:      4.25 m/s (15.3 km/h)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# MAIN PIPELINE\n",
    "def main():\n",
    "    print(\"Loading dataset...\")\n",
    "    ds = xr.open_dataset(DATA_PATH)\n",
    "    \n",
    "    # Find valid buoy location\n",
    "    buoy_lat, buoy_lon = find_nearest_ocean_point(ds, SPOT_LAT, SPOT_LON)\n",
    "    print(f\"Virtual buoy: ({buoy_lat:.2f}°N, {buoy_lon:.2f}°E)\")\n",
    "    \n",
    "    # Feature engineering\n",
    "    print(\"\\nEngineering features...\")\n",
    "    X, y = engineer_features(ds, buoy_lat, buoy_lon)\n",
    "    print(f\"Spatial input shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    \n",
    "    # Preprocessing\n",
    "    print(\"Preprocessing data...\")\n",
    "    X_scaled, y_scaled, scalers_X, scaler_y = preprocess_data(X, y)\n",
    "    \n",
    "    # Create sequences\n",
    "    print(f\"Creating sequences (lookback={LOOKBACK_HOURS}, lookahead={LOOKAHEAD_HOURS})...\")\n",
    "    X_seq, y_seq = create_sequences(X_scaled, y_scaled, LOOKBACK_HOURS, LOOKAHEAD_HOURS)\n",
    "    print(f\"Sequence shape: X={X_seq.shape}, y={y_seq.shape}\")\n",
    "    \n",
    "    # Build model\n",
    "    print(\"\\nBuilding model...\")\n",
    "    model = build_model(X_seq.shape[1:], y_seq.shape[1])\n",
    "    model.summary()\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nTraining for {EPOCHS} epochs...\")\n",
    "    history = model.fit(\n",
    "        X_seq, y_seq,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_size = int(VALIDATION_SPLIT * len(X_seq))\n",
    "    evaluate_model(\n",
    "        model, \n",
    "        X_seq[-val_size:], \n",
    "        y_seq[-val_size:], \n",
    "        scaler_y,\n",
    "        TARGET_VARS\n",
    "    )\n",
    "    \n",
    "    # Forecast next time step\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FORECAST (Next 6 Hours)\")\n",
    "    print(\"=\"*60)\n",
    "    last_seq = np.expand_dims(X_scaled[-LOOKBACK_HOURS:], axis=0)\n",
    "    forecast_scaled = model.predict(last_seq, verbose=0)\n",
    "    forecast = scaler_y.inverse_transform(forecast_scaled)[0]\n",
    "    \n",
    "    # Reconstruct direction from sin/cos\n",
    "    direction_deg = np.rad2deg(np.arctan2(forecast[2], forecast[3])) % 360\n",
    "    \n",
    "    print(f\"Swell Height:    {forecast[0]:.2f} m\")\n",
    "    print(f\"Swell Period:    {forecast[1]:.2f} s\")\n",
    "    print(f\"Swell Direction: {direction_deg:.1f}°\")\n",
    "    print(f\"Wind Speed:      {forecast[4]:.2f} m/s ({forecast[4]*3.6:.1f} km/h)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return model, history, scaler_y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, history, scaler = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

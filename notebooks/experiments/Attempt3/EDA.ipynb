{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32099550-f8a9-441f-9561-f8fdfe5082b9",
   "metadata": {},
   "source": [
    "### ERA5 Dataset \n",
    "The server splits the data you requested into separate files based on the type of variable and the model stream it comes from.\n",
    "Your request included variables from different categories, which the system packages separately. Hereâ€™s the breakdown:\n",
    "\n",
    "data_stream-oper_stepType-instant.nc (Atmospheric Instantaneous) : This file contains variables that represent a snapshot in time.\n",
    "Variables: 10m_u_component_of_wind, 10m_v_component_of_wind, mean_sea_level_pressure, sea_surface_temperature, total_cloud_cover.\n",
    "\n",
    "data_stream-oper_stepType-accum.nc (Atmospheric Accumulated) : This file contains variables that are accumulated or averaged over a time period. total_precipitation isn't an instantaneous value; it's the total rain that fell in the hours leading up to the timestamp (e.g., total rainfall between 00:00 and 06:00).\n",
    "Variables: total_precipitation.\n",
    "\n",
    "data_stream-wave_stepType-instant.nc (Wave Model Instantaneous) : This file contains variables generated by a separate wave model (WAM), not the primary atmospheric model.\n",
    "Variables: significant_height_of_combined_wind_waves_and_swell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44544081-81fa-4a06-a515-1f8cebfd3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "YEAR = \"2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36306364-e03e-48d6-86dd-d168eff23a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracted: surf_data_2024_01.nc\n",
      "  Extracted: surf_data_2024_02.nc\n",
      "  Extracted: surf_data_2024_03.nc\n",
      "  Extracted: surf_data_2024_04.nc\n",
      "  Extracted: surf_data_2024_05.nc\n",
      "  Extracted: surf_data_2024_06.nc\n",
      "  Extracted: surf_data_2024_07.nc\n",
      "  Extracted: surf_data_2024_08.nc\n",
      "  Extracted: surf_data_2024_09.nc\n",
      "  Extracted: surf_data_2024_10.nc\n",
      "  Extracted: surf_data_2024_11.nc\n",
      "  Extracted: surf_data_2024_12.nc\n"
     ]
    }
   ],
   "source": [
    "for month_num in range(1, 13):\n",
    "    month_str = f\"{month_num:02d}\"\n",
    "    extract_path = os.path.join(YEAR, month_str)\n",
    "    archive_path = os.path.join(extract_path, f\"surf_data_{YEAR}_{month_str}.nc\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(archive_path, 'r') as zip_file:\n",
    "            zip_file.extractall(path=extract_path)\n",
    "        print(f\"  Extracted: {os.path.basename(archive_path)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {os.path.basename(archive_path)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450b21bd-5918-467c-b2e4-0601c35e8eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing directory: 2024\\01\n",
      "  Processing directory: 2024\\02\n",
      "  Processing directory: 2024\\03\n",
      "  Processing directory: 2024\\04\n",
      "  Processing directory: 2024\\05\n",
      "  Processing directory: 2024\\06\n",
      "  Processing directory: 2024\\07\n",
      "  Processing directory: 2024\\08\n",
      "  Processing directory: 2024\\09\n",
      "  Processing directory: 2024\\10\n",
      "  Processing directory: 2024\\11\n",
      "  Processing directory: 2024\\12\n"
     ]
    }
   ],
   "source": [
    "list_of_monthly_datasets = []\n",
    "\n",
    "for month_num in range(1, 13):\n",
    "    month_str = f\"{month_num:02d}\"\n",
    "    month_directory = os.path.join(YEAR, month_str)\n",
    "    \n",
    "    print(f\"  Processing directory: {month_directory}\")\n",
    "\n",
    "    files_to_merge = [\n",
    "        os.path.join(month_directory, \"data_stream-oper_stepType-instant.nc\"),\n",
    "        os.path.join(month_directory, \"data_stream-oper_stepType-accum.nc\"),\n",
    "        os.path.join(month_directory, \"data_stream-wave_stepType-instant.nc\"),\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        datasets = []\n",
    "        for file_path in files_to_merge:\n",
    "            if os.path.exists(file_path):\n",
    "                ds_part = xr.open_dataset(file_path)\n",
    "                datasets.append(ds_part)\n",
    "        \n",
    "        if not datasets:\n",
    "            print(f\"    -> No data_stream files found to merge. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        combined_ds = xr.merge(datasets, compat='override')\n",
    "        cleaned_ds = combined_ds.dropna(dim=\"valid_time\", how=\"all\")\n",
    "        list_of_monthly_datasets.append(cleaned_ds)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65f78fe-a563-4542-8ea1-fafb02e426fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 16MB\n",
      "Dimensions:     (valid_time: 1464, latitude: 21, longitude: 21)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 12kB 2024-01-01 ... 2024-12-31T18...\n",
      "  * latitude    (latitude) float64 168B 5.0 5.25 5.5 5.75 ... 9.25 9.5 9.75 10.0\n",
      "  * longitude   (longitude) float64 168B 78.0 78.25 78.5 ... 82.5 82.75 83.0\n",
      "    number      int64 8B 0\n",
      "    expver      (valid_time) <U4 23kB '0001' '0001' '0001' ... '0001' '0001'\n",
      "Data variables:\n",
      "    u10         (valid_time, latitude, longitude) float32 3MB -4.375 ... -6.738\n",
      "    v10         (valid_time, latitude, longitude) float32 3MB -1.539 ... -6.051\n",
      "    msl         (valid_time, latitude, longitude) float32 3MB 1.011e+05 ... 1...\n",
      "    shts        (valid_time, latitude, longitude) float32 3MB 1.488 ... 1.261\n",
      "    mpts        (valid_time, latitude, longitude) float32 3MB 7.378 ... 7.853\n",
      "    mdts        (valid_time, latitude, longitude) float32 3MB 79.67 ... 120.2\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-26T13:55 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds = xr.concat(list_of_monthly_datasets, dim=\"valid_time\")\n",
    "    print(ds)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a70e27f-2b54-499f-82ff-82f87e4c323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to final csv\n",
    "output_filename = f\"surf_data_{YEAR}.nc\"\n",
    "ds.to_netcdf(output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

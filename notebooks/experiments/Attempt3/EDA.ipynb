{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32099550-f8a9-441f-9561-f8fdfe5082b9",
   "metadata": {},
   "source": [
    "### ERA5 Dataset \n",
    "The server splits the data you requested into separate files based on the type of variable and the model stream it comes from.\n",
    "Your request included variables from different categories, which the system packages separately. Hereâ€™s the breakdown:\n",
    "\n",
    "data_stream-oper_stepType-instant.nc (Atmospheric Instantaneous) : This file contains variables that represent a snapshot in time.\n",
    "Variables: 10m_u_component_of_wind, 10m_v_component_of_wind, mean_sea_level_pressure, sea_surface_temperature, total_cloud_cover.\n",
    "\n",
    "data_stream-oper_stepType-accum.nc (Atmospheric Accumulated) : This file contains variables that are accumulated or averaged over a time period. total_precipitation isn't an instantaneous value; it's the total rain that fell in the hours leading up to the timestamp (e.g., total rainfall between 00:00 and 06:00).\n",
    "Variables: total_precipitation.\n",
    "\n",
    "data_stream-wave_stepType-instant.nc (Wave Model Instantaneous) : This file contains variables generated by a separate wave model (WAM), not the primary atmospheric model.\n",
    "Variables: significant_height_of_combined_wind_waves_and_swell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44544081-81fa-4a06-a515-1f8cebfd3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "YEAR = \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36306364-e03e-48d6-86dd-d168eff23a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracted: surf_data_2020_01.nc\n",
      "  Extracted: surf_data_2020_02.nc\n",
      "  Extracted: surf_data_2020_03.nc\n",
      "  Extracted: surf_data_2020_04.nc\n",
      "  Extracted: surf_data_2020_05.nc\n",
      "  Extracted: surf_data_2020_06.nc\n",
      "  Extracted: surf_data_2020_07.nc\n",
      "  Extracted: surf_data_2020_08.nc\n",
      "  Extracted: surf_data_2020_09.nc\n",
      "  Extracted: surf_data_2020_10.nc\n",
      "  Extracted: surf_data_2020_11.nc\n",
      "  Extracted: surf_data_2020_12.nc\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT ALL MONTHLY ARCHIVES\n",
    "for month_num in range(1, 13):\n",
    "    month_str = f\"{month_num:02d}\"\n",
    "    # Define the path to the monthly archive and the directory to extract into\n",
    "    extract_path = os.path.join(YEAR, month_str)\n",
    "    archive_path = os.path.join(extract_path, f\"surf_data_{YEAR}_{month_str}.nc\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(archive_path, 'r') as zip_file:\n",
    "            zip_file.extractall(path=extract_path)\n",
    "        print(f\"  Extracted: {os.path.basename(archive_path)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {os.path.basename(archive_path)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450b21bd-5918-467c-b2e4-0601c35e8eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing directory: 2020\\01\n",
      "  Processing directory: 2020\\02\n",
      "  Processing directory: 2020\\03\n",
      "  Processing directory: 2020\\04\n",
      "  Processing directory: 2020\\05\n",
      "  Processing directory: 2020\\06\n",
      "  Processing directory: 2020\\07\n",
      "  Processing directory: 2020\\08\n",
      "  Processing directory: 2020\\09\n",
      "  Processing directory: 2020\\10\n",
      "  Processing directory: 2020\\11\n",
      "  Processing directory: 2020\\12\n"
     ]
    }
   ],
   "source": [
    "# MERGE EXTRACTED FILES\n",
    "list_of_monthly_datasets = []\n",
    "\n",
    "for month_num in range(1, 13):\n",
    "    month_str = f\"{month_num:02d}\"\n",
    "    month_directory = os.path.join(YEAR, month_str)\n",
    "    \n",
    "    print(f\"  Processing directory: {month_directory}\")\n",
    "\n",
    "    # Define the expected data_stream files within the directory\n",
    "    files_to_merge = [\n",
    "        os.path.join(month_directory, \"data_stream-oper_stepType-instant.nc\"),\n",
    "        os.path.join(month_directory, \"data_stream-oper_stepType-accum.nc\"),\n",
    "        os.path.join(month_directory, \"data_stream-wave_stepType-instant.nc\"),\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        datasets = []\n",
    "        # Load each data_stream file that exists\n",
    "        for file_path in files_to_merge:\n",
    "            if os.path.exists(file_path):\n",
    "                ds_part = xr.open_dataset(file_path)\n",
    "                datasets.append(ds_part)\n",
    "        \n",
    "        if not datasets:\n",
    "            print(f\"    -> No data_stream files found to merge. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        combined_ds = xr.merge(datasets, compat='override')\n",
    "        cleaned_ds = combined_ds.dropna(dim=\"valid_time\", how=\"all\")\n",
    "        list_of_monthly_datasets.append(cleaned_ds)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65f78fe-a563-4542-8ea1-fafb02e426fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 5MB\n",
      "Dimensions:     (valid_time: 1464, latitude: 11, longitude: 11)\n",
      "Coordinates:\n",
      "    number      int64 8B 0\n",
      "  * valid_time  (valid_time) datetime64[ns] 12kB 2020-01-01 ... 2020-12-31T18...\n",
      "  * latitude    (latitude) float64 88B 10.0 9.5 9.0 8.5 8.0 ... 6.5 6.0 5.5 5.0\n",
      "  * longitude   (longitude) float64 88B 78.0 78.5 79.0 79.5 ... 82.0 82.5 83.0\n",
      "    expver      (valid_time) <U4 23kB '0001' '0001' '0001' ... '0001' '0001'\n",
      "Data variables:\n",
      "    u10         (valid_time, latitude, longitude) float32 709kB 0.3915 ... -4...\n",
      "    v10         (valid_time, latitude, longitude) float32 709kB -1.084 ... -2...\n",
      "    msl         (valid_time, latitude, longitude) float32 709kB 1.013e+05 ......\n",
      "    sst         (valid_time, latitude, longitude) float32 709kB nan ... 302.0\n",
      "    tcc         (valid_time, latitude, longitude) float32 709kB 0.9592 ... 0....\n",
      "    tp          (valid_time, latitude, longitude) float32 709kB 1.907e-06 ......\n",
      "    swh         (valid_time, latitude, longitude) float32 709kB nan ... 2.072\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-17T16:54 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Concatenate all the monthly datasets into one for the entire year\n",
    "    ds = xr.concat(list_of_monthly_datasets, dim=\"valid_time\")\n",
    "    print(ds)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a70e27f-2b54-499f-82ff-82f87e4c323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to final csv\n",
    "output_filename = f\"surf_data_{YEAR}.nc\"\n",
    "ds.to_netcdf(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc63664-0e5c-4c2a-91fd-5fc9c654407b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
